{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used to calculate the slippage of a client's daily stock exchange.\n",
    "Though I belive my script is not directly used in the product of our company,\n",
    "some part of it may contain non-disclosable information of AQUMON, such as the netdisk's folder names.\n",
    "Therefore, I replaced some non-disclosable information by \"#\", thank you for inderstanding!\n",
    "\"\"\"\n",
    "# THE FIRST PART: importing packages and open the documents\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "# The following three are package made by AQUMON's quant team\n",
    "# Fortunately they are not used in the major part of the code\n",
    "from order_router import OrderRouter\n",
    "import qtoolkit \n",
    "import py_oms_client\n",
    "\n",
    "path = \"/Users/zimu/Documents/AQUMON_intern/account_data_forzimu/\"\n",
    "order_router = OrderRouter(account_dir=os.path.join(path, 'account/'), env_dir=os.path.join(path, 'env'))\n",
    "\n",
    "# Setting up the display here is to make it easier to see all the data\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Opening the NAS netdisk's files\n",
    "file_of_open = open(\"/Volumes/nfs_share/aqm_collect/###/###/adjust_open.csv\"\n",
    "                    , \"r\")\n",
    "file_of_close = open(\"/Volumes/nfs_share/aqm_collect/###/###/adjust_close.csv\"\n",
    "                     , \"r\")\n",
    "file_of_fac = open(\"/Volumes/nfs_share/aqm_collect/###/###/adjust_factor.csv\"\n",
    "                   , \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE SECOND PART: Extract all information from the webcam file. The files need to be opened before this part\n",
    "# This part should be divided into three functions\n",
    "# that return three dictionaries containing information about each of the three files.\n",
    "# Instead of using pandas, I used the csv package, \n",
    "# which converts each line of the file into a dict and runs faster than pandas.\n",
    "\n",
    "# This one is used to extract information about the open price\n",
    "def extract_open_info(file_of_open):\n",
    "    # Get all dates here. \n",
    "    # You can't use datetime because holidays are not included in the transaction dates. \n",
    "    # Globalize this list for later.\n",
    "    global all_dates\n",
    "    date_open_info = pd.read_csv(file_of_open, index_col=0)\n",
    "    all_dates = list(date_open_info.index)\n",
    "    return date_open_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is similar to the function above\n",
    "# This one is used to extract information about the close price\n",
    "def extract_close_info(file_of_close):\n",
    "    date_close_info = pd.read_csv(file_of_close, index_col=0)\n",
    "    return date_close_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is also similar to the function above\n",
    "# This one is used to extract the information about adjusting factors.\n",
    "def extract_fac_info(file_of_fac):\n",
    "    date_fac_info = pd.read_csv(file_of_fac, index_col=0)\n",
    "    return date_fac_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE THRID PART: Using pandas to synthesize information\n",
    "def synthesize_df(date_open_info, date_close_info, date_fac_info, account_name, today_date):\n",
    "    # Here we are obtaining the date of the previous day\n",
    "    yesterday_date = all_dates[all_dates.index(today_date) - 1] \n",
    "\n",
    "    # Open the following three things separately, order_router needs to be imported in the first section\n",
    "    today_trans_df = order_router.fetchTransactionHistory(account_name, today_date)\n",
    "    today_hold_df = order_router.fetchHoldingHistory(account_name, today_date)\n",
    "    yesterday_hold_df = order_router.fetchHoldingHistory(account_name, yesterday_date)\n",
    "\n",
    "    trade_time = int(str(list(today_trans_df[\"filledTime\"])[0])[11:13])\n",
    "    # Here use concat and merge to create synthesized DataFrame and add price, holding, factor information.\n",
    "    # But it's not enough, the information about the transaction, \n",
    "    # such as priceFilled, will involve multiple transactions with the same ID, \n",
    "    # resulting in multiple identical indexes, which can't be used with merge, \n",
    "    # and will have to be counted individually below.\n",
    "    synth_df = pd.concat([yesterday_hold_df.to_frame(\"yesterday_holdings\"),\n",
    "                          today_hold_df.to_frame(\"today_holdings\")], axis=1)\n",
    "    synth_df = pd.merge(left=synth_df, right=date_open_info.loc[today_date].to_frame(\"open_price\"),\n",
    "                        left_index=True, right_index=True, how=\"left\")\n",
    "    synth_df = pd.merge(left=synth_df, right=date_close_info.loc[yesterday_date].to_frame(\"yesterday_close_price\"),\n",
    "                        left_index=True, right_index=True, how=\"left\")\n",
    "    synth_df = pd.merge(left=synth_df, right=date_close_info.loc[today_date].to_frame(\"today_close_price\"),\n",
    "                        left_index=True, right_index=True, how=\"left\")\n",
    "    synth_df = pd.merge(left=synth_df, right=date_fac_info.loc[yesterday_date].to_frame(\"yesterday_fac\"),\n",
    "                        left_index=True, right_index=True, how=\"left\")\n",
    "    synth_df = pd.merge(left=synth_df, right=date_fac_info.loc[today_date].to_frame(\"today_fac\"),\n",
    "                        left_index=True, right_index=True, how=\"left\")\n",
    "    synth_df = synth_df.fillna(0)\n",
    "\n",
    "    # Here we are summing up the fees and volumes of multiple trades with the same ID, \n",
    "    # weighting the trades by price, and replacing the trade direction with -1 or 1.\n",
    "    # Create the following list ready to put data:\n",
    "    # column of direction, column of commission, column of priceFilled, column of holdingsFilled(or quantityFilled)\n",
    "    col_of_dire_bi, col_of_commission, col_of_pF, col_of_hF = [], [], [], []\n",
    "    # Create dicts with IDs corresponding to individual data\n",
    "    ID_to_wei, ID_to_yes_hol, ID_to_commission, ID_to_direction = {}, {}, {}, {}\n",
    "    # IDs that made trades today are derived below without repetition\n",
    "    today_ID = list(set(today_trans_df.index))\n",
    "    today_ID.sort()\n",
    "    for ID in today_ID:\n",
    "        # these three variables are going to increase by each iteration\n",
    "        weighted = 0\n",
    "        change = 0\n",
    "        commission = 0\n",
    "        try:\n",
    "            # If multiple transactions are involved, \n",
    "            # convert the corresponding IDs and their transaction prices, volumes, and fees into lists.\n",
    "            every_Pf = list(today_trans_df[\"priceFilled\"].loc[ID])\n",
    "            every_Hf = list(today_trans_df[\"quantityFilled\"].loc[ID])\n",
    "            every_commission = list(today_trans_df[\"commission\"].loc[ID])\n",
    "            # and convert the diraction of teansaction to 1 or -1.\n",
    "            every_dire = -1 if list(today_trans_df[\"direction\"].loc[ID])[0] == \"SELL\" else 1\n",
    "        except:\n",
    "            # If there is only a single transaction, \n",
    "            # it can't be directly converted to a list (because it's not iterable), \n",
    "            # but since we're going to use sum(list) below, \n",
    "            # we're going to use parentheses on both sides to convert to a list.\n",
    "            every_Pf = [today_trans_df[\"priceFilled\"].loc[ID]]\n",
    "            every_Hf = [today_trans_df[\"quantityFilled\"].loc[ID]]\n",
    "            every_commission = [today_trans_df[\"commission\"].loc[ID]]\n",
    "            # and convert the diraction of teansaction to 1 or -1.\n",
    "            every_dire = -1 if [today_trans_df[\"direction\"].loc[ID]][0] == \"SELL\" else 1\n",
    "        for i in range(len(every_Hf)):\n",
    "            weighted += (every_Pf[i] * every_Hf[i]) / sum(every_Hf)\n",
    "            change += every_Hf[i]\n",
    "            commission += every_commission[i]\n",
    "        # Now the weighted price, the volume, the commission, \n",
    "        # and the direction of the trade are all out and in the dict\n",
    "        ID_to_wei[ID] = weighted\n",
    "        ID_to_yes_hol[ID] = change\n",
    "        ID_to_commission[ID] = commission\n",
    "        ID_to_direction[ID] = every_dire\n",
    "    # Loop over all the IDs in my synthesized DataFrame.\n",
    "    # Since there may be no transactions that day, \n",
    "    # the looped IDs may not be in the transaction history, \n",
    "    # in which case the stats will be zero.\n",
    "    for ID in synth_df.index:\n",
    "        col_of_pF.append(ID_to_wei[ID] if ID in today_trans_df.index else 0.0)\n",
    "        col_of_hF.append(ID_to_yes_hol[ID] if ID in today_trans_df.index else 0.0)\n",
    "        col_of_commission.append(ID_to_commission[ID] if ID in today_trans_df.index else 0.0)\n",
    "        col_of_dire_bi.append(ID_to_direction[ID] if ID in today_trans_df.index else 0.0)\n",
    "\n",
    "    # Finally put all four into my synthesized DataFrame,\n",
    "    # and note that the transaction price is multiplied by the factor.\n",
    "    # where factor is used to deal with share split that changes the price of stocks.\n",
    "    synth_df[\"commission\"] = col_of_commission\n",
    "    synth_df[\"weighted_priceFilled\"] = col_of_pF\n",
    "    synth_df[\"quantityFilled\"] = col_of_hF\n",
    "    synth_df[\"direction_binary\"] = col_of_dire_bi\n",
    "    synth_df[\"weighted_priceFilled\"] = synth_df[\"weighted_priceFilled\"] * synth_df[\"today_fac\"]\n",
    "    # END OF THE THIRD PART\n",
    "    return synth_df, trade_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FOURTH PART: This part is mostly implementing formula\n",
    "def calculate_slip_and_pnl(synth_df, trade_time, account_name, today_date):\n",
    "    # Begin to implement formula\n",
    "    synth_df[\"delta_1_slippage\"] = (synth_df[\"direction_binary\"]) * synth_df[\"quantityFilled\"] * \\\n",
    "                                   (synth_df[\"yesterday_close_price\"] - synth_df[\"open_price\"]) / synth_df[\"today_fac\"]\n",
    "    synth_df[\"delta_1_slippage(%)\"] = synth_df[\"delta_1_slippage\"] / (synth_df[\"yesterday_close_price\"]\n",
    "                                                                      * synth_df[\"today_holdings\"])\n",
    "    synth_df[\"delta_2_slippage\"] = (synth_df[\"direction_binary\"]) * synth_df[\"quantityFilled\"] * \\\n",
    "                                   (synth_df[\"open_price\"] - synth_df[\"weighted_priceFilled\"]) / synth_df[\"today_fac\"]\n",
    "    synth_df[\"delta_2_slippage(%)\"] = synth_df[\"delta_2_slippage\"] / (synth_df[\"yesterday_close_price\"]\n",
    "                                                                      * synth_df[\"today_holdings\"])\n",
    "    # The first formula is the formula for transaction slippage\n",
    "    if trade_time < 14:\n",
    "        synth_df[\"trans_slippage\"] = (synth_df[\"direction_binary\"]) * synth_df[\"quantityFilled\"] / \\\n",
    "                                     synth_df[\"today_fac\"] * \\\n",
    "                                     (synth_df[\"yesterday_close_price\"] - synth_df[\"weighted_priceFilled\"])\n",
    "        synth_df[\"trans_slippage(%)\"] = synth_df[\"trans_slippage\"] / (synth_df[\"yesterday_close_price\"]\n",
    "                                                                      * synth_df[\"today_holdings\"])\n",
    "    else:\n",
    "        # If you got it after 14:00 pm, then replace yeaterday_close with today_close\n",
    "        synth_df[\"trans_slippage\"] = (synth_df[\"direction_binary\"]) * synth_df[\"quantityFilled\"] / \\\n",
    "                                     synth_df[\"today_fac\"] * \\\n",
    "                                     (synth_df[\"today_close_price\"] - synth_df[\"weighted_priceFilled\"])\n",
    "        synth_df[\"trans_slippage(%)\"] = synth_df[\"trans_slippage\"] / (synth_df[\"yesterday_close_price\"]\n",
    "                                                                      * synth_df[\"today_holdings\"])\n",
    "    # The second formula is the formula for pnl_real (real PnL)\n",
    "    # pnl refers to \"Profit and Loss\"\n",
    "    synth_df[\"pnl_real\"] = synth_df[\"yesterday_holdings\"] * \\\n",
    "                           (synth_df[\"weighted_priceFilled\"] - synth_df[\"yesterday_close_price\"]) / \\\n",
    "                           synth_df[\"yesterday_fac\"]+\\\n",
    "                           synth_df[\"today_holdings\"] * \\\n",
    "                           (synth_df[\"today_close_price\"] - synth_df[\"weighted_priceFilled\"]) / synth_df[\"today_fac\"]\n",
    "    synth_df[\"pnl_real(%)\"] = synth_df[\"trans_slippage\"] / (synth_df[\"yesterday_close_price\"]\n",
    "                                                            * synth_df[\"today_holdings\"])\n",
    "\n",
    "    # The third formula is the formula for pnl_naive (naive PnL)\n",
    "    # pnl refers to \"Profit and Loss\"\n",
    "    synth_df[\"pnl_naive\"] = synth_df[\"today_holdings\"] * \\\n",
    "                            (synth_df[\"today_close_price\"] - synth_df[\"yesterday_close_price\"]) / synth_df[\"today_fac\"]\n",
    "    synth_df[\"pnl_naive(%)\"] = synth_df[\"trans_slippage\"] / (synth_df[\"yesterday_close_price\"]\n",
    "                                                             * synth_df[\"today_holdings\"])\n",
    "    # Lastly, calculate the turnover\n",
    "    synth_df[\"trade_volume\"] = synth_df[\"quantityFilled\"] * synth_df[\"weighted_priceFilled\"] / synth_df[\"today_fac\"]\n",
    "    synth_df[\"turnover\"] = synth_df[\"trade_volume\"] / (synth_df[\"yesterday_close_price\"] * synth_df[\"today_holdings\"])\n",
    "    # get the last 12 columns, which I want to use.\n",
    "    # The name for those columns will be defined later\n",
    "    calculated_results_df = synth_df.iloc[:, -12:]\n",
    "    yesterday_date = all_dates[all_dates.index(today_date) - 1]\n",
    "    overall_cur_pv = order_router.fetchPVHistory(account_name, yesterday_date)\n",
    "    overall_delta_1 = sum(list(synth_df[\"delta_1_slippage\"]))\n",
    "    overall_delta_2 = sum(list(synth_df[\"delta_2_slippage\"]))\n",
    "    overall_trans_slip = sum(list(synth_df[\"trans_slippage\"]))\n",
    "    overall_pnl_real = sum(list(synth_df[\"pnl_real\"]))\n",
    "    overall_pnl_naive = sum(list(synth_df[\"pnl_naive\"]))\n",
    "    overall_trade_volume = sum(list(synth_df[\"trade_volume\"]))\n",
    "    calculated_results_df.loc[\"overall\"] = [f\"{overall_delta_1:.4f}\",\n",
    "                                            f\"{overall_delta_1 / overall_trade_volume:.4%}\",\n",
    "                                            f\"{overall_delta_2:.4f}\",\n",
    "                                            f\"{overall_delta_2 / overall_trade_volume:.4%}\",\n",
    "                                            f\"{overall_trans_slip:.4f}\",\n",
    "                                            f\"{overall_trans_slip / overall_trade_volume:.4%}\",\n",
    "                                            f\"{overall_pnl_real:.4f}\",\n",
    "                                            f\"{overall_pnl_real / overall_cur_pv:.4%}\",\n",
    "                                            f\"{overall_pnl_naive:.4f}\",\n",
    "                                            f\"{overall_pnl_naive / overall_cur_pv:.4%}\",\n",
    "                                            f\"{overall_trade_volume:.4f}\",\n",
    "                                            f\"{overall_trade_volume / overall_cur_pv:.4%}\"]\n",
    "    return calculated_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, write a csv file that covers all the data you want to count for the selected date range\n",
    "def produce_result_csv(account_name, start_date, end_date, open_info, close_info, fac_info):\n",
    "    produced_file = open(f\"slippage_and_pnl_of_{account_name}.csv\", \"wt\")\n",
    "    # Write out the first line of the header\n",
    "    produced_file.write(\"Dates,\"+\",\".join([\"delta_1($)\", \"delta_1(%)\", \"delta_2($)\", \"delta_2(%)\",\n",
    "                                           \"trans_slippage($)\", \"trans_slippage(%)\", \"pnl_real($)\", \"pnl_real(%)\",\n",
    "                                           \"pnl_naive($)\", \"pnl_naive(%)\", \"trade_volume\", \"turnover\"])+\"\\n\")\n",
    "    # Write up the data for each date\n",
    "    for dates in all_dates[all_dates.index(start_date): all_dates.index(end_date)+1]:\n",
    "        df, tradetime = synthesize_df(open_info, close_info, fac_info, account_name, dates)\n",
    "        final_df = calculate_slip_and_pnl(df, tradetime, account_name, dates)\n",
    "        produced_file.write(dates+\", \"+\", \".join(list(final_df.loc[\"overall\"]))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_info = extract_open_info(file_of_open)\n",
    "close_info = extract_close_info(file_of_close)\n",
    "fac_info = extract_fac_info(file_of_fac)\n",
    "produce_result_csv(\"######_momt\", \"2022-##-##\", \"2022-##-##\", open_info, close_info, fac_info)\n",
    "\n",
    "file_of_fac.close()\n",
    "file_of_close.close()\n",
    "file_of_fac.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddls1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
